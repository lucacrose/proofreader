--- FILE: .gitignore ---
# --- Model Weights & Training Artifacts ---
# PyTorch weights and YOLO models
*.pt

# --- YOLO/Ultralytics training runs ---
runs/

# --- Debug & Temporary Files ---
# Logs and temporary visualization outputs
debug_outputs/
debug_results/
*.cache
*.log

# --- Python Environment ---
__pycache__/
*.py[cod]
*$py.class
venv/
.env
*.egg-info/

# --- Build ---
build/*

# --- Assets ---
src/assets/thumbnails/*
!src/assets/thumbnails/.gitkeep
src/assets/weights/*
!src/assets/weights/.gitkeep
src/assets/db.json
src/assets/embedding_bank.pt

# --- Training ---
src/proofreader/train/emulator/backgrounds/*
!src/proofreader/train/emulator/backgrounds/.gitkeep
src/proofreader/train/emulator/templates/*
!src/proofreader/train/emulator/templates/.gitkeep
src/proofreader/train/dataset

--- END OF .gitignore ---

--- FILE: LICENSE ---
MIT License

Copyright (c) [2026] [Luca Rose]

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
--- END OF LICENSE ---

--- FILE: pyproject.toml ---
[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "rbx-proofreader"
version = "1.0.0"
description = "Visual trade detection and OCR engine"
readme = "README.md"
requires-python = ">=3.12"
license = {text = "MIT"}
dependencies = [
    "easyocr>=1.7.0",
    "numpy>=1.24.0",
    "opencv-python>=4.8.0",
    "Pillow>=10.0.0",
    "playwright>=1.40.0",
    "rapidfuzz>=3.0.0",
    "requests>=2.31.0",
    "torch>=2.0.0",
    "tqdm>=4.66.0",
    "transformers>=4.30.0",
    "ultralytics>=8.0.0"
]

[tool.setuptools]
package-dir = {"" = "src"}

[tool.setuptools.packages.find]
where = ["src"]
include = ["proofreader*"]

--- END OF pyproject.toml ---

--- FILE: README.md ---
# Proofreader ðŸ”
High-speed Roblox trade analyzer using **YOLOv11**, **CLIP**, and **EasyOCR** for instant item detection and structured JSON output.

![Python](https://img.shields.io/badge/python-3.12-blue.svg)
![YOLOv11](https://img.shields.io/badge/model-YOLOv11-green.svg)
![License](https://img.shields.io/badge/license-MIT-red.svg)
![PyPI](https://img.shields.io/pypi/v/rbx-proofreader?color=blue&label=PyPI)
![Build](https://img.shields.io/badge/build-passing-brightgreen)

---

## Features
- Detect outgoing and incoming trade items from screenshots
- Outputs structured JSON for automation or analytics
- Supports custom backgrounds and HTML templates
- Trained with YOLOv11 and enhanced with CLIP embeddings
- Easy installation and integration

---

## Example

| Input Image | Detected UI Elements |
| ----------- | ------------------ |
| ![](./docs/assets/trade_before.png) | ![](./docs/assets/trade_after.png) |

**Sample Output JSON:**

```json
{
    "outgoing": {
        "item_count": 4,
        "robux_value": 0,
        "items": [
            {"id": 1031429, "name": "Domino Crown"},
            {"id": 72082328, "name": "Red Sparkle Time Fedora"},
            {"id": 124730194, "name": "Blackvalk"},
            {"id": 16652251, "name": "Red Tango"}
        ]
    },
    "incoming": {
        "item_count": 2,
        "robux_value": 1048576,
        "items": [
            {"id": 21070012, "name": "Dominus Empyreus"},
            {"id": 22850569, "name": "Red Bandana of SQL Injection"}
        ]
    }
}
```

## ðŸ’» Quick Start

```py
import proofreader

# Analyze the image
data = proofreader.get_trade_data("test.png")

# Print the result
print(data)
```

## Installation

### Quick Install (Recommended)

```bash
pip install rbx-proofreader
```

### From Source (Advanced / Custom Training)

**1.** Clone the repository.

**2.** Run `python scripts/setup_items.py` to initialize cache, download thumbnails, and create CLIP embeddings.

**3.** Place background images in: `src/proofreader/train/emulator/backgrounds`. Use continuous numbering: background_0.jpg, background_1.jpg, ...

**4.** Place HTML templates in `src/proofreader/train/emulator/templates`. Include both light and dark theme templates.

**5.** Configure synthetic data generation and YOLO training settings in `src/proofreader/core/config.py`


**6.** Run `python scripts/train_model.py`

> Note: GPU recommended for training. Final model will be saved under `runs/trainX/weights/best.pt`. Rename to `yolo.pt` and move to `src/assets/weights`.

## Tech Stack

- **Python 3.12**

- **YOLOv11** for fast UI detection

- **CLIP** for visual embedding matching

- **EasyOCR** for text extraction

- **NumPy / OpenCV** for image processing

## Contributing

Contributions are welcome! Please open an issue or submit a pull request.

## License

This project is licensed under the MIT License.
--- END OF README.md ---

--- FILE: requirements.txt ---
-e .

--- END OF requirements.txt ---

--- FILE: .github\workflows\publish.yml ---
name: Publish to PyPI

on:
  release:
    types: [published]

jobs:
  build-n-publish:
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
      - name: Build
        run: |
          pip install build
          python -m build
      - name: Publish
        uses: pypa/gh-action-pypi-publish@release/v1

--- END OF .github\workflows\publish.yml ---

--- FILE: docs\assets\trade_after.png ---
PNG
SOURCE
--- END OF docs\assets\trade_before.png ---

--- FILE: scripts\setup_items.py ---
import requests
import json
import os
import shutil
from tqdm import tqdm
from transformers import CLIPProcessor, CLIPModel
from concurrent.futures import ThreadPoolExecutor
from concurrent.futures import ThreadPoolExecutor
from proofreader.core.config import THUMBNAILS_DIR, TRAIN_THUMBNAILS_DIR, DB_PATH, DEVICE
from proofreader.train.builder import EmbeddingBuilder

embedding_builder = EmbeddingBuilder(CLIPModel.from_pretrained("openai/clip-vit-base-patch32").to(DEVICE), CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32", use_fast=True))

THUMBNAILS_DIR.mkdir(parents=True, exist_ok=True)

def fetch_all_ids():
    unique_items = {}

    print("Fetching from Rolimons...")
    try:
        r_roli = requests.get("https://www.rolimons.com/itemapi/itemdetails")
        roli_data = r_roli.json()["items"]
        for item_id, details in roli_data.items():
            unique_items[int(item_id)] = details[0]
    except Exception as e:
        print(f"Rolimons fetch failed: {e}")
    
    print("Fetching from Roblox Catalog...")
    cursor = ""
    while True:
        url = f"https://catalog.roblox.com/v2/search/items/details?taxonomy=tZsUsd2BqGViQrJ9Vs3Wah&creatorName=Roblox&salesTypeFilter=2&includeNotForSale=true&limit=120&cursor={cursor}"
        resp = requests.get(url)
        if resp.status_code != 200: break
        
        data = resp.json()
        for item in data.get("data", []):
            item_id = int(item["id"])
            if item_id not in unique_items:
                unique_items[item_id] = item["name"]

        cursor = data.get("nextPageCursor")
        if not cursor: break
        print(f"Advanced to cursor: {cursor[:10]}...")

    return unique_items

def _download_single_image(thumb, pbar):
    target_id = thumb["targetId"]
    img_url = thumb["imageUrl"]
    img_path = THUMBNAILS_DIR / f"{target_id}.png"
    
    if not img_path.exists() and thumb.get("state") == "Completed":
        try:
            img_data = requests.get(img_url, timeout=10).content
            with open(img_path, "wb") as f:
                f.write(img_data)
        except Exception:
            pass
    
    pbar.update(1)

def download_thumbnails(item_ids):
    id_list = list(item_ids)
    to_download = [tid for tid in id_list if not (THUMBNAILS_DIR / f"{tid}.png").exists()]
    
    if not to_download:
        print("âœ… All thumbnails already exist.")
        return
    
    all_thumbs = []
    print(f"ðŸ“¡ Fetching metadata for {len(to_download)} items...")

    for i in tqdm(range(0, len(to_download), 100), desc="Metadata"):
        batch = to_download[i : i + 100]
        ids_str = ",".join(map(str, batch))
        url = f"https://thumbnails.roblox.com/v1/assets?assetIds={ids_str}&size=420x420&format=Png&isCircular=false"
        
        try:
            resp = requests.get(url).json()
            all_thumbs.extend(resp.get("data", []))
        except Exception as e:
            print(f"Error: {e}")
    
    print(f"ðŸ’¾ Downloading {len(all_thumbs)} images...")

    with tqdm(total=len(all_thumbs), desc="Downloading") as pbar:
        with ThreadPoolExecutor(max_workers=15) as executor:
            [executor.submit(_download_single_image, thumb, pbar) for thumb in all_thumbs]

    print("âœ¨ Finished!")

def save_database(unique_items):
    out = [{"id": int(k), "name": v} for k, v in unique_items.items()]
    with open(DB_PATH, "w") as f:
        json.dump(out, f, separators=(',', ':'))
    print(f"Database saved to {DB_PATH}")

    return out

def organize_files(id_to_name):
    os.makedirs(TRAIN_THUMBNAILS_DIR, exist_ok=True)

    for filename in os.listdir(THUMBNAILS_DIR):
        if filename.endswith(".png"):
            item_id = filename.split(".")[0]
            if item_id in id_to_name:
                class_folder = os.path.join(TRAIN_THUMBNAILS_DIR, item_id)
                os.makedirs(class_folder, exist_ok=True)
                shutil.copy(os.path.join(THUMBNAILS_DIR, filename), class_folder)

    print(f"Organized images into {len(os.listdir(TRAIN_THUMBNAILS_DIR))} classes.")

if __name__ == "__main__":
    all_items = fetch_all_ids()

    database = save_database(all_items)

    organize_files(database)

    download_thumbnails(all_items.keys())

    #if not os.path.exists(CACHE_PATH):
        #embedding_builder.build()
    #elif os.path.getmtime(THUMBNAILS_DIR) > os.path.getmtime(CACHE_PATH):
        #embedding_builder.build()
    
    print("Setup Complete! Your repo is now populated with data assets.")

--- END OF scripts\setup_items.py ---

--- FILE: scripts\train_model.py ---
from proofreader.train.emulator.generator import run_mass_generation
from proofreader.train.train import train_model

if __name__ == "__main__":
    run_mass_generation()
    train_model(0) # Change from 0 -> "cpu" if no CUDA devices

--- END OF scripts\train_model.py ---

--- FILE: src\assets\thumbnails\.gitkeep ---

--- END OF src\assets\thumbnails\.gitkeep ---

--- FILE: src\assets\weights\.gitkeep ---

--- END OF src\assets\weights\.gitkeep ---

--- FILE: src\proofreader\main.py ---
import os
import cv2
import torch
import json
import requests
from tqdm import tqdm
from transformers import CLIPProcessor, CLIPModel
from .core.detector import TradeDetector
from .core.resolver import SpatialResolver
from .core.ocr import OCRReader
from .core.matcher import VisualMatcher
from .core.config import DB_PATH, CACHE_PATH, MODEL_PATH, DEVICE

class TradeEngine:
    def __init__(self):
        self._ensure_assets()

        if DEVICE == "cpu" and not torch.cuda.is_available():
            import subprocess
            try:
                subprocess.check_output('nvidia-smi')
                print("Detected NVIDIA GPU, but your current Torch installation is CPU-only.")
                print("To fix this, run: pip install --force-reinstall torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128")
            except:
                pass

        self.device = DEVICE

        self.clip_model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32").to(self.device)
        self.clip_processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32", use_fast=True)
        
        with open(DB_PATH, "r") as f:
            item_db = json.load(f)
        
        cache_data = torch.load(CACHE_PATH, weights_only=False)['embeddings']
        self.embeddings = {k: torch.tensor(v).to(self.device) for k, v in cache_data.items()}

        self.detector = TradeDetector(MODEL_PATH)
        self.resolver = SpatialResolver()
        
        self.reader = OCRReader(item_db)
        
        self.matcher = VisualMatcher(
            embedding_bank=self.embeddings,
            item_db=item_db,
            clip_processor=self.clip_processor,
            clip_model=self.clip_model,
            device=self.device
        ) 

    def _ensure_assets(self):
        BASE_URL = "https://github.com/lucacrose/proofreader/releases/latest/download"
        
        assets = {
            DB_PATH: f"{BASE_URL}/db.json",
            CACHE_PATH: f"{BASE_URL}/embedding_bank.pt",
            MODEL_PATH: f"{BASE_URL}/yolo.pt"
        }

        for path, url in assets.items():
            if not path.exists():
                print(f"ðŸ“¦ {path.name} missing. Downloading from latest release...")
                self._download_file(url, path)

    def _download_file(self, url, dest_path):
        response = requests.get(url, stream=True)
        total_size = int(response.headers.get('content-length', 0))
        
        with open(dest_path, "wb") as f, tqdm(
            total=total_size, unit='B', unit_scale=True, desc=dest_path.name
        ) as pbar:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)
                pbar.update(len(chunk))

    def process_image(self, image_path: str, conf_threshold: float) -> dict:
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"Image not found: {image_path}")
        
        boxes = self.detector.detect(image_path, conf_threshold)
        layout = self.resolver.resolve(boxes)

        image = cv2.imread(image_path)

        self.reader.process_layout(image, layout)

        self.matcher.match_item_visuals(image, layout)

        return layout.to_dict()

--- END OF src\proofreader\main.py ---

--- FILE: src\proofreader\__init__.py ---
from .main import TradeEngine

_engine = None

def get_trade_data(image_path: str, conf_threshold: float = 0.25):
    global _engine
    if _engine is None:
        _engine = TradeEngine()
    
    return _engine.process_image(image_path, conf_threshold)

__all__ = ["get_trade_data"]

--- END OF src\proofreader\__init__.py ---

--- FILE: src\proofreader\core\config.py ---
import torch
import shutil
from pathlib import Path

# --- BASE PATHS ---
# Resolves to the 'proofreader' root directory
BASE_DIR = Path(__file__).resolve().parent.parent.parent

# --- ASSETS & MODELS ---
ASSETS_PATH = BASE_DIR / "assets"
MODEL_PATH = ASSETS_PATH / "weights" / "yolo.pt"
DB_PATH = ASSETS_PATH / "db.json"
CACHE_PATH = ASSETS_PATH / "embedding_bank.pt"
THUMBNAILS_DIR = ASSETS_PATH / "thumbnails"
TRAIN_THUMBNAILS_DIR = ASSETS_PATH / "train_data"

# --- TRAINING & EMULATOR ---
TRAIN_DIR = BASE_DIR / "proofreader" / "train"
DATA_YAML_PATH = TRAIN_DIR / "config" / "data.yaml"
DATASET_ROOT = TRAIN_DIR / "dataset"

EMULATOR_DIR = TRAIN_DIR / "emulator"
TEMPLATES_DIR = EMULATOR_DIR / "templates"
BACKGROUNDS_DIR = EMULATOR_DIR / "backgrounds"
AUGMENTER_PATH = EMULATOR_DIR / "augmenter.js"
DEFAULT_TEMPLATE = TEMPLATES_DIR / "trade_ui.html"

# --- HYPERPARAMETERS (Training Settings) ---
TRAINING_CONFIG = {
    "epochs": 100,             # Number of times the model sees the whole dataset
    "batch_size": 16,          # Number of images processed at once
    "img_size": 640,           # Standard YOLO resolution
    "patience": 10,            # Stop early if no improvement for 10 epochs
    "close_mosaic_epochs": 10  # Disable mosaic augmentation for the last N epochs
}

# --- AUGMENTER PROBABILITIES AND GENERATOR SETTINGS ---
AUGMENTER_CONFIG = {
    "name": {
        "space_chance": 0.15,           # Chance a character in a randomly generated name is a space
        "double_spacing": False,        # Whether consecutive spaces are allowed in names
    },
    "background": {
        "chance": 0.75,                 # Chance the page background is set to a random image
    },
    "recolor": {
        "chance": 0.75,                 # Chance container background and text are recolored and opacity-adjusted
        "container_min_opacity": 0.3,   # Minimum opacity for container background
        "container_max_opacity": 1.0,   # Maximum opacity for container background
        "text_min_opacity": 0.95,       # Minimum opacity for text inside container
        "text_max_opacity": 1.0,        # Maximum opacity for text inside container
    },
    "cards": {
        "name_hide_chance": 0.2,             # Chance the item card name is hidden
        "thumbnail_hide_chance": 0.2,        # Chance the thumbnail is hidden
        "line_height_min": 12,                # Minimum pixels for item name line height
        "line_height_max": 28,                # Maximum pixels for item name line height
        "left_offset_min": 0,                 # Minimum left margin for name/price offset
        "left_offset_max": 24,                # Maximum left margin for name/price offset
        "top_offset_min": 0,                  # Minimum top margin for name/price offset
        "top_offset_max": 12,                 # Maximum top margin for name/price offset
        "duplicate_price_line_chance": 0.35,  # Chance an item card gets an extra price line
        "display_serial_chance": 0.5,         # Chance the limited icon displays a serial number
    },
    "robux_lines": {
        "colon_suffix_chance": 0.5,       # Chance a robux line ends with a colon
        "duplicate_line_chance": 0.3,     # Chance a second robux line will generate for a side
        "hide_chance": 0.25,              # Chance an individual robux line is hidden
    },
    "generator": {
        "aspect_ratio_min": 1.0,           # Minimum allowed aspect ratio (width / height)
        "aspect_ratio_max": 2.4,           # Maximum allowed aspect ratio
        "width_min": 800,                  # Minimum width in pixels
        "width_max": 2560,                 # Maximum width in pixels
        "height_min": 400,                 # Minimum height in pixels (after aspect ratio calculation)
        "height_max": 1600,                # Maximum height in pixels (after aspect ratio calculation)
        "total_images": 1024,              # Total number of images to generate
        "max_workers": 16,                 # Maximum number of parallel workers for generation
        "train_split_fraction": 0.8,       # Fraction of images used for training vs validation
        "empty_trade_chance": 0.09,        # Chance a trade has no items or robux (negative sample)
    }
}

# Robustness Thresholds
FUZZY_MATCH_CONFIDENCE_THRESHOLD = 60.0
VISUAL_MATCH_THRESHOLD = 0.88

# --- HARDWARE SETTINGS ---
# Automatically detects if a GPU is available for faster training
if torch.cuda.is_available():
    DEVICE = "cuda"
elif torch.backends.mps.is_available():
    DEVICE = "mps"
else:
    DEVICE = "cpu"

BUILDER_BATCH_SIZE = 32

# OCR Settings
OCR_LANGUAGES = ['en']
OCR_USE_GPU = (DEVICE == "cuda" or DEVICE == "mps")

# --- DYNAMIC ASSETS ---
# Resolve template files once during import
if TEMPLATES_DIR.exists():
    TEMPLATE_FILES = [
        str(f.resolve())
        for f in TEMPLATES_DIR.iterdir()
        if f.is_file() and f.name != ".gitkeep"
    ]
else:
    TEMPLATE_FILES = []

# --- UTILITIES ---

def setup_dataset_directories(force_reset=False):
    dirs = [
        DATASET_ROOT / "train" / "images",
        DATASET_ROOT / "train" / "labels",
        DATASET_ROOT / "val" / "images",
        DATASET_ROOT / "val" / "labels",
    ]

    if force_reset and DATASET_ROOT.exists():
        shutil.rmtree(DATASET_ROOT)
        
    for d in dirs:
        d.mkdir(parents=True, exist_ok=True)
        
    return DATASET_ROOT

def ensure_base_directories():
    required_dirs = [
        ASSETS_PATH / "weights",
        TRAIN_DIR / "config",
        THUMBNAILS_DIR
    ]
    for directory in required_dirs:
        directory.mkdir(parents=True, exist_ok=True)

# Run base setup on import
ensure_base_directories()

--- END OF src\proofreader\core\config.py ---

--- FILE: src\proofreader\core\detector.py ---
from typing import List
from ultralytics.models import YOLO
from .schema import Box

class TradeDetector:
    def __init__(self, model_path: str):
        self.model = YOLO(model_path)
        
        self.class_map = {
            0: "item_card",
            1: "item_thumb",
            2: "item_name",
            3: "robux_line",
            4: "robux_value"
        }

    def detect(self, image_source: str, conf_threshold: float) -> List[Box]:
        results = self.model.predict(image_source, conf=conf_threshold, verbose=False)[0]

        detected_boxes = []

        for box in results.boxes:
            coords = tuple(map(int, box.xyxy[0].tolist()))
            conf = float(box.conf[0])
            cls_id = int(box.cls[0])

            label = self.class_map.get(cls_id, f"unknown_{cls_id}")

            detected_boxes.append(Box(
                coords=coords,
                label=label,
                confidence=conf
            ))

        return detected_boxes

--- END OF src\proofreader\core\detector.py ---

--- FILE: src\proofreader\core\matcher.py ---
import torch
import numpy as np
import cv2
from PIL import Image
from typing import Dict, List, Any
from .schema import TradeLayout
from proofreader.core.config import VISUAL_MATCH_THRESHOLD

class VisualMatcher:
    def __init__(self, embedding_bank: Dict[str, np.ndarray], item_db: List[dict], clip_processor: Any, clip_model: Any, device: str = "cuda"):
        self.device = device
        self.bank = embedding_bank
        self.item_db = item_db
        self.clip_processor = clip_processor
        self.clip_model = clip_model

        self.name_to_id = {str(i["name"]).lower().strip(): i["id"] for i in item_db}
        self.id_to_name = {str(i["id"]): i["name"] for i in item_db}

        self.bank_names = list(embedding_bank.keys())
        self.bank_tensor = torch.stack([embedding_bank[name] for name in self.bank_names]).to(self.device)
        self.bank_tensor = torch.nn.functional.normalize(self.bank_tensor, dim=1)

    def _get_id_from_name(self, name: str) -> str:
        item = next((i for i in self.item_db if i["name"] == name), None)
        return item["id"] if item else 0

    def match_item_visuals(self, image: np.ndarray, layout: TradeLayout, similarity_threshold: float = VISUAL_MATCH_THRESHOLD):
        items_to_process = []
        crops = []
        
        for side in (layout.outgoing.items, layout.incoming.items):
            for item in side:
                if item.thumb_box:
                    x1, y1, x2, y2 = item.thumb_box.coords
                    crop = image[y1:y2, x1:x2]
                    if crop.size > 0:
                        pil_img = Image.fromarray(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))
                        crops.append(pil_img)
                        items_to_process.append(item)

        if not crops:
            return
        
        inputs = self.clip_processor(images=crops, return_tensors="pt", padding=True).to(self.device)
        
        with torch.no_grad():
            query_features = self.clip_model.get_image_features(**inputs)
            query_features = torch.nn.functional.normalize(query_features, dim=1)
            similarities = torch.matmul(query_features, self.bank_tensor.T)
            best_scores, best_indices = torch.max(similarities, dim=1)
        
        for i, item in enumerate(items_to_process):
            visual_match_val = self.bank_names[best_indices[i]]
            visual_conf = best_scores[i].item()

            is_ocr_valid = item.name.lower().strip() in self.name_to_id if item.name else False

            if (not is_ocr_valid or visual_conf > 0.95) and visual_conf >= similarity_threshold:
                if str(visual_match_val).isdigit():
                    item.id = int(visual_match_val)
                    item.name = self.id_to_name.get(str(visual_match_val), "Unknown Item")
                else:
                    item.name = visual_match_val
                    item.id = self._get_id_from_name(visual_match_val)
            else:
                item.id = self._get_id_from_name(item.name)

--- END OF src\proofreader\core\matcher.py ---

--- FILE: src\proofreader\core\ocr.py ---
import cv2
import easyocr
import numpy as np
import re
from rapidfuzz import process, utils
from .schema import Box, TradeLayout, TradeSide
from proofreader.core.config import FUZZY_MATCH_CONFIDENCE_THRESHOLD, OCR_LANGUAGES, OCR_USE_GPU

class OCRReader:
    def __init__(self, item_list, languages=OCR_LANGUAGES, gpu=OCR_USE_GPU):
        self.reader = easyocr.Reader(languages, gpu=gpu)

        self.item_names = []

        for item in item_list:
            self.item_names.append(item["name"])

    def _fuzzy_match_name(self, raw_text: str, threshold: float = FUZZY_MATCH_CONFIDENCE_THRESHOLD) -> str:
        if not raw_text or len(raw_text) < 2:
            return raw_text
        
        match = process.extractOne(
            raw_text, 
            self.item_names, 
            processor=utils.default_process
        )

        if match and match[1] >= threshold:
            return match[0]
        
        return raw_text

    def _clean_robux_text(self, raw_text: str) -> int:
        cleaned = raw_text.upper().strip()

        substitutions = {
            ',': '', '.': '', ' ': '',
            'S': '5', 'O': '0', 'I': '1', 
            'L': '1', 'B': '8', 'G': '6'
        }

        for char, sub in substitutions.items():
            cleaned = cleaned.replace(char, sub)
        
        digits = re.findall(r'\d+', cleaned)

        return int("".join(digits)) if digits else 0

    def _get_text_from_box(self, image: np.ndarray, box: Box, is_robux: bool = False) -> str:
        x1, y1, x2, y2 = box.coords

        crop = image[max(0, y1-2):y2+2, max(0, x1-2):x2+2]
        
        if crop.size == 0:
            return ""
        
        gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)
        
        if is_robux:
            gray = cv2.resize(gray, None, fx=3, fy=3, interpolation=cv2.INTER_CUBIC)
            results = self.reader.readtext(gray, allowlist="0123456789,S ")
        else:
            results = self.reader.readtext(gray)
            
        return " ".join([res[1] for res in results]).strip()

    def process_side(self, image: np.ndarray, side: TradeSide):
        for item in side.items:
            if item.name_box:
                raw_name = self._get_text_from_box(image, item.name_box)
                item.name = self._fuzzy_match_name(raw_name)

        if side.robux and side.robux.value_box:
            raw_val = self._get_text_from_box(image, side.robux.value_box, is_robux=True)
            side.robux.value = self._clean_robux_text(raw_val)

    def process_layout(self, image: str, layout: TradeLayout):
        self.process_side(image, layout.outgoing)
        self.process_side(image, layout.incoming)

--- END OF src\proofreader\core\ocr.py ---

--- FILE: src\proofreader\core\resolver.py ---
from typing import List
from .schema import Box, ResolvedItem, ResolvedRobux, TradeLayout

class SpatialResolver:
    def __init__(self):
        pass

    def get_center(self, box: Box):
        x1, y1, x2, y2 = box.coords
        return (x1 + x2) / 2, (y1 + y2) / 2
    
    def is_contained(self, child: Box, parent: Box, margin: int = 20) -> bool:
        cx1, cy1, cx2, cy2 = child.coords
        px1, py1, px2, py2 = parent.coords
        
        return (cx1 >= px1 - margin and 
                cy1 >= py1 - margin and 
                cx2 <= px2 + margin and 
                cy2 <= py2 + margin)

    def resolve(self, all_boxes: List[Box]) -> TradeLayout:
        layout = TradeLayout()

        cards = [b for b in all_boxes if b.label == "item_card"]
        robux_lines = [b for b in all_boxes if b.label == "robux_line"]
        
        names = [b for b in all_boxes if b.label == "item_name"]
        thumbs = [b for b in all_boxes if b.label == "item_thumb"]
        values = [b for b in all_boxes if b.label == "robux_value"]

        parents = cards + robux_lines
        if not parents:
            return layout

        y_centers = sorted([self.get_center(p)[1] for p in parents])
        
        if len(y_centers) > 1:
            max_gap = -1
            gap_index = 0

            for i in range(len(y_centers) - 1):
                gap = y_centers[i + 1] - y_centers[i]
                if gap > max_gap:
                    max_gap = gap
                    gap_index = i + 1
            
            first_bottom_parent = next(p for p in parents if self.get_center(p)[1] == y_centers[gap_index])
            split_y = first_bottom_parent.coords[1] - 10
        else:
            split_y = y_centers[0] + 100

        for card in cards:
            item = ResolvedItem(container_box=card)
            item.name_box = next((n for n in names if self.is_contained(n, card)), None)
            item.thumb_box = next((t for t in thumbs if self.is_contained(t, card)), None)

            if self.get_center(card)[1] < split_y:
                layout.outgoing.items.append(item)
            else:
                layout.incoming.items.append(item)

        for line in robux_lines:
            val_box = next((v for v in values if self.is_contained(v, line)), None)
            
            if val_box:
                robux_obj = robux_obj = ResolvedRobux(
                    container_box=line,
                    value_box=val_box
                )

                if self.get_center(line)[1] < split_y:
                    layout.outgoing.robux = robux_obj 
                else:
                    layout.incoming.robux = robux_obj

        return layout

--- END OF src\proofreader\core\resolver.py ---

--- FILE: src\proofreader\core\schema.py ---
from dataclasses import dataclass, field
from typing import List, Tuple, Optional

@dataclass
class Box:
    coords: Tuple[int, int, int, int]
    label: str
    confidence: float

@dataclass
class ResolvedItem:
    name: str = "Unknown"
    id: int = 0
    container_box: Optional[Box] = None
    thumb_box: Optional[Box] = None
    name_box: Optional[Box] = None

@dataclass
class ResolvedRobux:
    value: int = 0
    container_box: Optional[Box] = None
    value_box: Optional[Box] = None

@dataclass
class TradeSide:
    items: List[ResolvedItem] = field(default_factory=list)
    robux: Optional[ResolvedRobux] = None

@dataclass
class TradeLayout:
    outgoing: TradeSide = field(default_factory=TradeSide)
    incoming: TradeSide = field(default_factory=TradeSide)

    def to_dict(self, row_tolerance=16) -> dict:
        def serialize_side(side: TradeSide):
            robux_val = side.robux.value if side.robux else 0
            
            if not side.items:
                return {"item_count": 0, "robux_value": robux_val, "items": []}
            
            raw_items = [it for it in side.items if it.container_box]
            raw_items.sort(key=lambda x: x.container_box.coords[1])

            rows = []
            if raw_items:
                current_row = [raw_items[0]]
                for i in range(1, len(raw_items)):
                    prev_y = current_row[-1].container_box.coords[1]
                    curr_y = raw_items[i].container_box.coords[1]
                    
                    if abs(curr_y - prev_y) < row_tolerance:
                        current_row.append(raw_items[i])
                    else:
                        rows.append(current_row)
                        current_row = [raw_items[i]]
                rows.append(current_row)
            
            final_sorted = []
            for row in rows:
                row.sort(key=lambda x: x.container_box.coords[0])
                final_sorted.extend(row)

            return {
                "item_count": len(side.items),
                "robux_value": robux_val,
                "items": [
                    {"id": item.id, "name": item.name} 
                    for item in final_sorted
                ]
            }

        return {
            "outgoing": serialize_side(self.outgoing),
            "incoming": serialize_side(self.incoming)
        }

--- END OF src\proofreader\core\schema.py ---

--- FILE: src\proofreader\core\__init__.py ---

--- END OF src\proofreader\core\__init__.py ---

--- FILE: src\proofreader\train\builder.py ---
import os
import json
import torch
from PIL import Image
from ..core.config import DB_PATH, CACHE_PATH, THUMBNAILS_DIR, BUILDER_BATCH_SIZE

class EmbeddingBuilder:
    def __init__(self, model, processor):
        self.model = model
        self.processor = processor

    def get_clip_embedding(self, pil_img):
        inputs = self.processor(images=pil_img, return_tensors="pt", padding=True).to(self.model.device)
        with torch.no_grad():
            features = self.model.get_image_features(**inputs)
        return features.cpu().numpy().flatten()

    def build(self, batch_size=BUILDER_BATCH_SIZE):
        self.model.eval()
        print(f"Starting build process...")
        print(f"Source Images: {THUMBNAILS_DIR}")
        print(f"Item Database: {DB_PATH}")
        
        if not os.path.exists(DB_PATH):
            print(f"Error: Missing {DB_PATH}. Cannot map IDs to Names.")
            return
            
        with open(DB_PATH, "r") as f:
            items = json.load(f)
        
        embedding_bank = {}
        item_names = []
        
        if not os.path.exists(THUMBNAILS_DIR):
            print(f"Error: Image directory {THUMBNAILS_DIR} not found.")
            return

        image_files = [f for f in os.listdir(THUMBNAILS_DIR) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        total_files = len(image_files)
        
        embedding_bank = {}
        item_names = []

        for i in range(0, total_files, batch_size):
            batch_files = image_files[i : i + batch_size]
            batch_imgs = []
            batch_item_names = []

            for filename in batch_files:
                item_id = os.path.splitext(filename)[0]
                item_info = next((item for item in items if str(item.get("id")) == item_id), None)
                
                if item_info:
                    try:
                        img_path = os.path.join(THUMBNAILS_DIR, filename)
                        raw_img = Image.open(img_path)

                        if raw_img.mode in ("RGBA", "P"):
                            bg = Image.new("RGB", raw_img.size, (255, 255, 255))
                            bg.paste(raw_img.convert("RGBA"), (0, 0), raw_img.convert("RGBA"))
                            img = bg
                        else:
                            img = raw_img.convert("RGB")
                            
                        batch_imgs.append(img)
                        batch_item_names.append(item_info["name"])
                    except Exception as e:
                        print(f"Could not load {filename}: {e}")

            if not batch_imgs:
                continue
            try:
                inputs = self.processor(images=batch_imgs, return_tensors="pt", padding=True).to(self.model.device)
                with torch.no_grad():
                    features = self.model.get_image_features(**inputs)
                
                features_numpy = features.cpu().numpy()
                for name, emb in zip(batch_item_names, features_numpy):
                    embedding_bank[name] = emb
                    item_names.append(name)
                
                print(f"Progress: {min(i + batch_size, total_files)}/{total_files} items indexed...")
            except Exception as e:
                print(f"Batch processing error: {e}")
        
        output_data = {
            'embeddings': embedding_bank, 
            'names': item_names
        }
        
        torch.save(output_data, CACHE_PATH)
        print(f"\nâœ… Build Complete!")
        print(f"Target: {CACHE_PATH}")
        print(f"Total Embeddings Saved: {len(embedding_bank)}")

--- END OF src\proofreader\train\builder.py ---

--- FILE: src\proofreader\train\train.py ---
from ultralytics import YOLO
from ..core.config import TRAINING_CONFIG, DATA_YAML_PATH

def train_model(device):
    model = YOLO("yolo11n.pt")

    model.train(
        data = DATA_YAML_PATH,
        epochs = TRAINING_CONFIG["epochs"],
        imgsz = TRAINING_CONFIG["img_size"],
        device = device,
        plots = True,
        multi_scale = True,

        batch = TRAINING_CONFIG["batch_size"],
        patience = TRAINING_CONFIG["patience"],

        box = 7.5,
        dfl = 1.5,
        cls = 1.5,

        mosaic = 0.7,
        mixup = 0.05,
        close_mosaic = TRAINING_CONFIG["close_mosaic_epochs"],

        overlap_mask = False,
        workers = 8
    )

def finish_training(file_path):
    model = YOLO(file_path)

    model.train(
        data = DATA_YAML_PATH,
        epochs = 32,
        close_mosaic = 32,
        patience = 20,
        imgsz = 640,
        batch = 24,
        device = 0 # Change to "cpu" if no CUDA devices
    )

if __name__ == "__main__":
    train_model()

--- END OF src\proofreader\train\train.py ---

--- FILE: src\proofreader\train\config\data.yaml ---
path: ./dataset
train: train/images
val: val/images

names:
  0: item_card
  1: item_thumb
  2: item_name
  3: robux_line
  4: robux_value

--- END OF src\proofreader\train\config\data.yaml ---

--- FILE: src\proofreader\train\emulator\augmenter.js ---
([newItems, is_empty_trade, backgrounds_count, config]) => {
    function generateRandomUsername() {
        const chars = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789_";
        const length = Math.floor(Math.random() * (20 - 3 + 1)) + 3;
        
        let result = "";
        for (let i = 0; i < length; i++) {
            result += chars.charAt(Math.floor(Math.random() * chars.length));
        }
        return result;
    }

    function getRandomInt(min, max) {
        min = Math.ceil(min);
        max = Math.floor(max);
        return Math.floor(Math.random() * (max - min + 1)) + min;
    }
    
    function getRandomNumberEqualDigits(minDigits = 1, maxDigits = 5) {
        const digits = getRandomInt(minDigits, maxDigits);
        const min = digits === 1 ? 0 : Math.pow(10, digits - 1);
        const max = Math.pow(10, digits) - 1;
        return getRandomInt(min, max);
    }
    
    function getRandomColor(alphaMin = 0.3, alphaMax = 1) {
        const r = Math.floor(Math.random() * 256);
        const g = Math.floor(Math.random() * 256);
        const b = Math.floor(Math.random() * 256);
        const a = (Math.random() * (alphaMax - alphaMin) + alphaMin).toFixed(2);
        return `rgba(${r}, ${g}, ${b}, ${a})`;
    }

    function randomAlphanumericWithSpaces(min = 2, max = 48) {
        const chars = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789";
        const length = Math.floor(Math.random() * (max - min + 1)) + min;

        let result = chars[Math.floor(Math.random() * chars.length)];

        for (let i = 1; i < length; i++) {
            if (!config.name.double_spacing && result[result.length - 1] === " ") {
                result += chars[Math.floor(Math.random() * chars.length)];
            } else {
            result += Math.random() < config.name.space_chance
                ? " "
                : chars[Math.floor(Math.random() * chars.length)];
            }
        }

        return result;
    }

    const randomIndex = getRandomInt(0, backgrounds_count - 1);
    const randomBgUrl = `url('../backgrounds/background_${randomIndex}.jpg')`;

    if (Math.random() < config.background.chance) {
        const container = document.querySelector(".container-main");
        container.style.backgroundImage = randomBgUrl;
        container.style.backgroundSize = "cover";
        container.style.backgroundPosition = "center";
        container.style.backgroundRepeat = "no-repeat";
    }

    if (Math.random() < config.recolor.chance) {
        const content = document.querySelector(".content");
        content.style.backgroundColor = getRandomColor(config.recolor.container_min_opacity, config.recolor.container_max_opacity);
        content.style.color = getRandomColor(config.recolor.text_min_opacity, config.recolor.text_max_opacity);
    }
    
    const nameElements = document.querySelectorAll('.paired-name .element');
    nameElements[0].innerText = generateRandomUsername();
    nameElements[1].innerText = generateRandomUsername();
            
    const cards = document.querySelectorAll('div[trade-item-card]');
    cards.forEach((card, index) => {
        const isFirstSide = index < 4;
        const sideIndex = isFirstSide ? 0 : 1;
        const itemIndex = isFirstSide ? index : index - 4;
        const data = newItems[sideIndex][itemIndex];
        const hideName = Math.random() < config.cards.name_hide_chance;
        const hideThumb = Math.random() < config.cards.thumb_hide_chance;

        if (data) {
            card.style.visibility = "visible";
            card.style.opacity = "1";
            card.setAttribute("data-item-id", data.id);

            const img = card.querySelector('img');
            img.src = data;

            const priceLabel = card.querySelector('.text-robux');
            priceLabel.innerText = getRandomNumberEqualDigits(1, 9).toLocaleString();

            const priceLine = priceLabel.closest('.item-card-price');

            if (
                priceLine &&
                Math.random() < config.cards.duplicate_price_line_chance &&
                !priceLine.nextElementSibling?.classList.contains('item-card-price')
            ) {
                const clone = priceLine.cloneNode(true);

                const cloneValue = clone.querySelector('.text-robux');
                cloneValue.innerText = getRandomNumberEqualDigits(1, 9).toLocaleString();

                priceLine.parentElement.insertBefore(clone, priceLine.nextSibling);
            }

            const nameLabel = card.querySelector('.item-card-name');
            nameLabel.innerText = randomAlphanumericWithSpaces();
            nameLabel.style.lineHeight = `${getRandomInt(config.cards.line_height_min, config.line_height_max)}px`;

            if (hideName) nameLabel.style.display = "none";
            if (hideThumb) img.parentElement.parentElement.parentElement.parentElement.style.display = "none";
        } else {
            card.style.opacity = "0"; 
            card.setAttribute("data-item-id", "");
        }
    });
    
    const robuxLines = document.querySelectorAll(".robux-line");
    robuxLines[0].style.display = is_empty_trade ? "none" : (Math.random() < config.robux_lines.hide_chance ? "none" : "");
    robuxLines[2].style.display = is_empty_trade ? "none" : (Math.random() < config.robux_lines.hide_chance ? "none" : "");
            
    document.querySelectorAll(".robux-line-value").forEach(el => {
        el.textContent = getRandomNumberEqualDigits(1, 10).toLocaleString();
    });

    document.querySelectorAll(".limited-icon-container").forEach(container => {
        const numberContainer = container.querySelector(".limited-number-container");
        const numberSpan = container.querySelector(".limited-number");
        if (!numberContainer || !numberSpan) return;
        const show = Math.random() < config.cards.display_serial_chance;
        if (show) {
            numberContainer.style.display = "";
            numberSpan.style.display = "";
            numberSpan.textContent = getRandomNumberEqualDigits(1, 7);
        } else {
            numberContainer.style.display = "none";
            numberSpan.style.display = "none";
        }
    });
            
    document.querySelectorAll('.item-card-name, .item-card-price').forEach(el => {
        const offsetLeft = Math.floor(getRandomInt(config.cards.left_offset_min, config.cards.left_offset_max))
        const offsetTop = Math.floor(getRandomInt(config.cards.top_offset_min, config.cards.top_offset_max));
        el.style.marginLeft = `${offsetLeft}px`;
        el.style.marginTop = `${offsetTop}px`;
    });
    
    const withColon = text =>
    Math.random() < config.robux_lines.colon_suffix_chance ? `${text}:` : text;

    document.querySelectorAll('.trade-list-detail-offer').forEach(offer => {
        if (Math.random() > config.robux_lines.duplicate_line_chance) return;

        if (offer.querySelector('.robux-line.total-rap')) return;

        const robuxLines = [...offer.querySelectorAll('.robux-line')];

        const totalValueLine = robuxLines.find(line =>
            line.querySelector('.text-lead')?.textContent
            .replace(/:/g, '')
            .trim() === 'Total Value'
        );

        if (!totalValueLine) return;

        const valueLabel = totalValueLine.querySelector('.text-lead');
        if (valueLabel) {
            valueLabel.textContent = withColon('Total Value');
        }

        const rapValue = [...offer.querySelectorAll('.item-card-price .text-robux')]
            .reduce((sum, el) => sum + Number(el.textContent.replace(/,/g, '')), 0)
            .toLocaleString();
        
        const rapLine = document.createElement('div');
        rapLine.className = 'robux-line total-rap';
        rapLine.innerHTML = `
            <span class="text-lead">${withColon('Total RAP')}</span>
            <span class="robux-line-amount">
            <span class="icon-robux-16x16"></span>
            <span class="text-robux-lg robux-line-value">${rapValue}</span>
            </span>
        `;

        totalValueLine.parentElement.insertBefore(rapLine, totalValueLine);
    });
}

--- END OF src\proofreader\train\emulator\augmenter.js ---

--- FILE: src\proofreader\train\emulator\generator.py ---
import json
import random
import concurrent.futures
import sys
import traceback
from pathlib import Path
from playwright.sync_api import sync_playwright
from tqdm import tqdm
import cv2
import numpy as np

ROOT_DIR = Path(__file__).resolve().parent.parent.parent
sys.path.insert(0, str(ROOT_DIR))

from proofreader.core.config import (
    AUGMENTER_PATH, 
    DATASET_ROOT, 
    TEMPLATE_FILES, 
    AUGMENTER_CONFIG, 
    DB_PATH, 
    BACKGROUNDS_DIR, 
    setup_dataset_directories
)

GENERATOR_CONFIG = AUGMENTER_CONFIG["generator"]

def worker_task(task_id, db, backgrounds_count):
    try:
        split = "train" if random.random() < GENERATOR_CONFIG["train_split_fraction"] else "val"
        output_name = f"trade_{task_id:05d}"

        img_dir = DATASET_ROOT / split / "images"
        lbl_dir = DATASET_ROOT / split / "labels"
        img_dir.mkdir(parents=True, exist_ok=True)
        lbl_dir.mkdir(parents=True, exist_ok=True)

        trade_input = [[], []]
        is_empty_trade = random.random() < GENERATOR_CONFIG["empty_trade_chance"]

        if not is_empty_trade:
            for side in [0, 1]:
                num_items = random.randint(0, 4)
                for _ in range(num_items):
                    item = random.choice(db)
                    trade_input[side].append(f"../../../../assets/thumbnails/{item['id']}.png")
        
        with open(AUGMENTER_PATH, 'r', encoding="utf-8") as f:
            augmenter_js = f.read()

        with sync_playwright() as p:
            browser = p.chromium.launch(headless=True)

            aspect_ratio = random.uniform(GENERATOR_CONFIG["aspect_ratio_min"], GENERATOR_CONFIG["aspect_ratio_max"])
            width = random.randint(GENERATOR_CONFIG["width_min"], GENERATOR_CONFIG["width_max"])
            height = int(width / aspect_ratio)
            height = max(GENERATOR_CONFIG["height_min"], min(height, GENERATOR_CONFIG["height_max"]))
            
            context = browser.new_context(viewport={"width": width, "height": height})
            page = context.new_page()

            random_file = random.choice(TEMPLATE_FILES)
            page.goto(f"file://{Path(random_file).absolute()}")

            page.evaluate(augmenter_js, [trade_input, is_empty_trade, backgrounds_count, AUGMENTER_CONFIG])

            def get_padded_yolo(element, class_id, pad_px=2):
                box = element.bounding_box()
                if not box: return None
                
                x1 = max(0, box['x'] - pad_px)
                y1 = max(0, box['y'] - pad_px)
                x2 = min(width, box['x'] + box['width'] + pad_px)
                y2 = min(height, box['y'] + box['height'] + pad_px)
                
                new_w = x2 - x1
                new_h = y2 - y1
                center_x = x1 + (new_w / 2)
                center_y = y1 + (new_h / 2)
                
                return [class_id, center_x / width, center_y / height, new_w / width, new_h / height]

            def is_fully_visible(box, width, height, pad=4):
                return (box['x'] - pad >= 0 and 
                        box['y'] - pad >= 0 and 
                        (box['x'] + box['width'] + pad) <= width and 
                        (box['y'] + box['height'] + pad) <= height)
            
            label_data = []

            items = page.query_selector_all("div[trade-item-card]")
            for item in items:
                box = item.bounding_box()
                if box and is_fully_visible(box, width, height):
                    card_box = get_padded_yolo(item, 0, pad_px=4)
                    if card_box: label_data.append(card_box)

                    thumb = item.query_selector(".item-card-thumb-container") 
                    if thumb:
                        thumb_box = get_padded_yolo(thumb, 1, pad_px=4)
                        if thumb_box: label_data.append(thumb_box)
                    
                    name = item.query_selector(".item-card-name")
                    if name:
                        name_box = get_padded_yolo(name, 2, pad_px=4)
                        if name_box: label_data.append(name_box)
            
            robux_sections = page.query_selector_all(".robux-line:not(.total-value)")
            for section in robux_sections:
                box = section.bounding_box()
                if box and is_fully_visible(box, width, height, 8) and section.is_visible():
                    line_box = get_padded_yolo(section, 3, pad_px=8)
                    if line_box: label_data.append(line_box)

                    value_element = section.query_selector(".robux-line-value") 
                    if value_element:
                        value_box = get_padded_yolo(value_element, 4, pad_px=4)
                        if value_box: label_data.append(value_box)
            
            img_path = img_dir / f"{output_name}.png"
            page.screenshot(path=str(img_path))

            if random.random() < 0.60:
                img = cv2.imread(str(img_path))
                if img is not None:
                    if random.random() < 0.5:
                        quality = random.randint(60, 90) 
                        _, encimg = cv2.imencode('.jpg', img, [int(cv2.IMWRITE_JPEG_QUALITY), quality])
                        img = cv2.imdecode(encimg, 1)
                    
                    if random.random() < 0.4:
                        alpha = random.uniform(0.8, 1.2)
                        beta = random.randint(-20, 20)
                        img = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)
                    
                    level = random.uniform(0.5, 2.5) 
                    noise = np.random.normal(0, level, img.shape).astype('float32')
                    img = np.clip(img.astype('float32') + noise, 0, 255).astype('uint8')
                    cv2.imwrite(str(img_path), img)
            
            label_path = lbl_dir / f"{output_name}.txt"
            with open(label_path, "w") as f:
                for label in label_data:
                    f.write(f"{label[0]} {label[1]:.6f} {label[2]:.6f} {label[3]:.6f} {label[4]:.6f}\n")

            browser.close()

    except Exception:
        print(f"Error generating task {task_id}:")
        traceback.print_exc()

def run_mass_generation(total_images=GENERATOR_CONFIG["total_images"], max_workers=GENERATOR_CONFIG["max_workers"]):
    bg_files = [f for f in BACKGROUNDS_DIR.iterdir() if f.is_file() and f.name != ".gitkeep"]
    if not bg_files:
        print(f"âŒ ERROR: No background images found in {BACKGROUNDS_DIR}")
        print("Please add background images (JPG/PNG) to the folder before running.")
        return
    
    valid_templates = [
        t for t in TEMPLATE_FILES 
        if Path(t).exists() and Path(t).name != ".gitkeep"
    ]
    if not valid_templates:
        print(f"âŒ ERROR: No valid HTML templates found. Checked: {TEMPLATE_FILES}")
        print("Ensure your template files exist and are not just .gitkeep placeholders.")
        return
    
    if not DB_PATH.exists():
        print(f"âŒ ERROR: Item database missing at {DB_PATH}")
        return
    
    with open(DB_PATH, "r") as f:
        db = json.load(f)
    
    backgrounds_count = len([f for f in BACKGROUNDS_DIR.iterdir() if f.is_file()]) - 1

    setup_dataset_directories(force_reset=True)

    print(f"Starting generation of {total_images} images using {max_workers} processes...")

    with concurrent.futures.ProcessPoolExecutor(max_workers=max_workers) as executor:
        futures = [executor.submit(worker_task, i, db, backgrounds_count) for i in range(total_images)]
        for _ in tqdm(concurrent.futures.as_completed(futures), total=total_images):
            pass

if __name__ == "__main__":
    run_mass_generation(total_images=16, max_workers=8)

--- END OF src\proofreader\train\emulator\generator.py ---

--- FILE: src\proofreader\train\emulator\backgrounds\.gitkeep ---

--- END OF src\proofreader\train\emulator\backgrounds\.gitkeep ---

--- FILE: src\proofreader\train\emulator\templates\.gitkeep ---

--- END OF src\proofreader\train\emulator\templates\.gitkeep ---

